\section{方法}
\label{sec:methodology}
在本研究中，我们旨在探讨预训练语言模型在特定的数学任务上的应用潜力，特别是通过结合不同的微调技术和数据增强策略来优化模型性能。我们的目标是有效利用现有资源，在不显著增加计算成本的前提下，测试Qwen2.5系列模型\citep{qwen2.5}的表现。我们以Qwen2.5-0.5B的监督微调为一个稳健的基线模型，然后依次探索低秩适应（LoRA）、前缀调优（Prefix Tuning）等参数高效微调技术，以及反思增强（Reflective Augmentation）等数据扩充方法的效果。此外，我们还将评估专家模型在资源受限条件下的表现，以全面了解参数量和数据类型对模型性能的影响。
\subsection{基线模型微调}
\textbf{监督微调与基线建立。} 我们首先构建了一个基线模型，该模型基于Qwen2.5-0.5B，并分别在GSM8K\citep{cobbe2021training}和MATH\citep{hendrycksmath2021}两个数据集上进行了监督微调（Supervised Fine-Tuning, SFT）。这两个数据集分别聚焦于基础算术问题解决能力和高等数学推理能力，为模型提供了全面而深入的学习材料。

\subsection{参数高效微调}
\textbf{低秩适应（Low-Rank Adaptation, LoRA）。} 为了在有限计算资源下提升模型性能，我们引入了低秩适应（LoRA）技术 \citep{hu2022lora}。LoRA通过仅更新预训练模型权重矩阵的低秩近似部分来减少需要调整的参数数量，从而降低内存和计算需求，同时提高特定任务上的性能。这种方法特别适合资源受限环境。

\textbf{前缀调优（Prefix Tuning）。} 我们还应用了前缀调优（Prefix Tuning）技术 \citep{li2021prefixtuning} 来改进微调效率。前缀调优通过在输入序列前添加可训练的前缀向量，引导模型生成符合新任务需求的输出，而不直接修改原模型参数。这种方法减少了训练时间和显存占用，避免了灾难性遗忘，并允许模型灵活适应多种下游任务。。

\subsection{查询(Query)和响应(Response)增强与数据扩充}
\textbf{查询响应增强以扩充数据集。} 在探索提升数学推理任务中大型语言模型的性能时，我们意识到数据增强是提高模型泛化能力的关键。因此，我们应用了Li\citep{li2023query}提出的数据增强技术，通过演化查询（query evolution）和多样化推理路径来扩充数据集。这种方法不仅增加了数据集的规模，而且通过引入更复杂和多样化的问题表述以及多个推理路径，创建了两个新数据集AugGSM8K和AugMATH，提高了数据的质量。我们在这些扩充数据集上进行的监督式微调进一步优化了性能。

\subsection{专家模型}
\textbf{模型的选择。} 尽管理想情况下我们希望对更大规模的模型进行全面微调，但实际操作中却面临着设备显存等硬件资源的限制。为此，我们特别选择了Qwen2.5-MATH-1.5B这一专门为数学领域优化的模型进行实验。该模型不仅拥有更多的参数量，而且是在一个更为专业的数学数据集上训练而成，这使得我们可以探讨参数量和数据类型对于预训练模型性能的具体影响。